# ğŸ§  RAG Multilingual QA System

A simple **Retrieval-Augmented Generation (RAG)** pipeline that answers questions in **English and Arabic** using 3â€“5 sample documents with **citations**.  
This project fulfills **Task 3 â€” RAG Knowledge Base (AR/EN)** from the *AI Integration Engineer Practical Task Pack*.

---


## ğŸ¯ Project Overview

The goal of this task is to build a **simple Q&A system** over a few documents (public or dummy).  
When a user asks a question in English or Arabic, the system retrieves the most relevant parts of the documents and generates an answer, showing **which files (sources)** the information came from.

**Pipeline:**  
`ingest â†’ chunk â†’ embed â†’ index (FAISS/Chroma/pgvector) â†’ query â†’ cite sources`

---


## ğŸ§© Features

- Supports **English and Arabic** questions  
- Uses **FAISS** for vector search  
- Runs locally in **mock mode** (no API key required)  
- Optional **FastAPI web interface**  
- Includes **latency and cost report**  
- Clean, modular, and fully documented  
- Works with **OpenAI API** or local **SentenceTransformer** embeddings  

---


## ğŸ“‚ Project Structure

```text
rag-multilingual-qa-system/
â”‚
â”œâ”€â”€ data/                             # 10 text documents (5 English + 5 Arabic)
â”‚   â”œâ”€â”€ product_catalog_en.txt
â”‚   â”œâ”€â”€ product_catalog_ar.txt
â”‚   â”œâ”€â”€ warranty_policy_en.txt
â”‚   â”œâ”€â”€ warranty_policy_ar.txt
â”‚   â”œâ”€â”€ safety_manual_en.txt
â”‚   â”œâ”€â”€ safety_manual_ar.txt
â”‚   â”œâ”€â”€ company_policy_en.txt
â”‚   â”œâ”€â”€ company_policy_ar.txt
â”‚   â”œâ”€â”€ technical_specs_en.txt
â”‚   â””â”€â”€ technical_specs_ar.txt
â”‚
â”œâ”€â”€ src/                              # Main application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ indexer.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ cli_app.py
â”‚   â””â”€â”€ web_app.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_mock_mode.py
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ build_index.py
â”œâ”€â”€ qa_cli.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ latency_report.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Project_Detail.pdf
â””â”€â”€ README.md

---


## âš™ï¸ Tech Stack

| **Component**          | **Tool / Technology**                              |
|-------------------------|----------------------------------------------------|
| Language                | Python 3.10+                                       |
| Framework               | FastAPI (for Web API)                              |
| Vector Database          | FAISS                                              |
| Embedding Models         | OpenAI API / Sentence-Transformers                 |
| Configuration Management | python-dotenv                                     |
| Testing Framework        | pytest                                            |
| Language Detection       | langdetect                                        |
| Environment Isolation    | virtualenv / venv                                |
| Version Control          | Git + GitHub                                      |
| Deployment Option        | Docker (optional, local/remote build supported)  |


---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/rag-multilingual-qa-system.git
cd rag-multilingual-qa-system

### 2ï¸âƒ£ Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate      # For macOS/Linux
venv\Scripts\activate         # For Windows

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt


### 4ï¸âƒ£ Configure Environment
```bash
cp .env.example .env

```ini
USE_MOCK=true
OPENAI_API_KEY=your_api_key_here
DATA_DIR=data
INDEX_PATH=vector_index.faiss
EMBED_MODEL=all-MiniLM-L6-v2
VECTOR_DB=faiss



## ğŸ§® How to Run

### Step 1 â€” Build the Index
```bash
python build_index.py

### Step 2 â€” Ask Questions (CLI)
```bash
python src/cli_app.py --q "What is the delivery time for ALR-SL-90W?" --lang en
python src/cli_app.py --q "ÙƒÙ… Ù…Ø¯Ø© Ø§Ù„ØªØ³Ù„ÙŠÙ…ØŸ" --lang ar


### Step 3 â€” Run as Web API
```bash
uvicorn src.web_app:app --reload --port 8000


### 4ï¸âƒ£ Configure Environment
```bash
cp .env.example .env



ğŸ§ª Testing
- Run all tests:
- pytest tests/



Tests cover:
- Mock mode pipeline (no API key)
- Index creation
- English/Arabic query retrieval
- Citation formatting



ğŸ“Š Latency and Cost Report
Step	                     Avg Time (ms)	       Cost (USD/query)
Embedding	                   45	                      0.0001
FAISS Search	               12                       	0
Answer Generation (Mock)	   100                        	0
Total	                       â‰ˆ157 ms	              â‰ˆ$0.0001/query

Mode: Mock (no external calls)
Hardware: Local CPU (8 GB RAM)



ğŸ§¾ Deliverables Checklist (as per Task 3)
Requirement                                                 	Status
3â€“5 sample documents (AR/EN)	                           âœ… 10 provided
Simple Q&A with citations	                               âœ… Implemented
Ingest â†’ Chunk â†’ Embed â†’ Index â†’ Query â†’ Cite	           âœ… Complete
CLI or minimal web UI	                                   âœ… Both
Latency/Cost report	                                       âœ… Provided
Runnable without secrets	                               âœ… Mock mode supported
README & .env.example	                                   âœ… Included
3â€“7 min video walkthrough	                               âœ… Included



ğŸ§‘â€ğŸ’» Author
- Ansh Srivastava
- Candidate â€” AI, Automation & Integration Engineer 
- Tools: Python Â· FAISS Â· FastAPI Â· Sentence-Transformers Â· OpenAI API



ğŸ Summary
- This project demonstrates:
- The ability to implement a Retrieval-Augmented Generation (RAG) pipeline
- Handling bilingual (AR/EN) documents
- Building a lightweight, testable, documented system with clear citations